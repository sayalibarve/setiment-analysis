{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SentimentAnalysisProject.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcinnOomCfS2",
        "colab_type": "text"
      },
      "source": [
        "Project of Sentiment Analysis on labelled dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAG12MfJ2UZP",
        "colab_type": "code",
        "outputId": "5f08c5b2-6ac2-44e4-b7aa-9f32e0e1b0e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import TensorDataset, DataLoader"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hIdjdC45z3d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filepath = 'SJ_Unsupervised_NLP_data.txt'\n",
        "df = pd.read_csv(filepath,delimiter='\\t',names=['review', 'label'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ycgk7TupBoUF",
        "colab_type": "text"
      },
      "source": [
        "Pre processing I - Removing punctuations, special characters, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXzg8P2y5_8l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "review = df.iloc[:, 0].values\n",
        "label = df.iloc[:, 1].values\n",
        "\n",
        "processed_reviews = []\n",
        "\n",
        "for sentence in range(0, len(review)):\n",
        "    processed_rev = re.sub(r'[^\\w\\s]', '', str(review[sentence]))\n",
        "    processed_rev= re.sub(r'\\s+[a-zA-Z]\\s+', ' ', processed_rev)\n",
        "    processed_rev = re.sub(r'\\s+', ' ', processed_rev, flags=re.I)\n",
        "    processed_rev = re.sub(r'\\d+', ' ', processed_rev)\n",
        "    processed_rev = processed_rev.lower()\n",
        "    processed_reviews.append(processed_rev)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5re3VoD68Y6",
        "colab_type": "code",
        "outputId": "21cc2a61-cc17-453c-c578-f97a58ad36fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "data_clean = pd.DataFrame(processed_reviews)\n",
        "data_clean.columns = ['reviews']\n",
        "data_clean['senti_score'] = label\n",
        "data_clean.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviews</th>\n",
              "      <th>senti_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>so there is no way for me to plug it in here i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>good case excellent value</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>great for the jawbone</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tied to charger for conversations lasting more...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>the mic is great</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             reviews  senti_score\n",
              "0  so there is no way for me to plug it in here i...            0\n",
              "1                          good case excellent value            1\n",
              "2                              great for the jawbone            1\n",
              "3  tied to charger for conversations lasting more...            0\n",
              "4                                   the mic is great            1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSNW1W69B_7j",
        "colab_type": "text"
      },
      "source": [
        "Pre processing II - Removing stopwords, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dp6sikGK7equ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stopword = stopwords.words('english')\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    text = text.split()\n",
        "    text = [word for word in text if not word in stopword]\n",
        "    return text\n",
        "\n",
        "def count_words(words):\n",
        "  return Counter(words)\n",
        "\n",
        "def split_in_words(no_punct_text):\n",
        "    temp = \" \".join(no_punct_text)\n",
        "    split_text = temp.split(' ')\n",
        "    return split_text\n",
        "\n",
        "words = split_in_words(np.asarray(data_clean['reviews']))\n",
        "words = [word for word in words if not word in stopword]\n",
        "count = count_words(words)\n",
        "clean_data = data_clean['reviews'].apply(lambda x:remove_stopwords(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xK0IyqOBIof",
        "colab_type": "text"
      },
      "source": [
        "Making vocabulary out of words in the train data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkdG3bhO8Luq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vocabulary(counts):\n",
        "    vocab = {}\n",
        "    sorted_counts = sorted(counts, key= counts.get, reverse=True)\n",
        "    counter = 1\n",
        "    for word in sorted_counts:\n",
        "        vocab.update({counter:word})\n",
        "        counter += 1\n",
        "    return vocab\n",
        "\n",
        "def vocabulary_to_integer(vocab):\n",
        "    vocab_to_int = {}\n",
        "    counter = 1\n",
        "    for word in vocab:\n",
        "        vocab_to_int.update({vocab[word]:counter})\n",
        "        counter += 1\n",
        "    return vocab_to_int\n",
        "\n",
        "vocab = vocabulary(count)\n",
        "vocab_to_int = vocabulary_to_integer(vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gou_x0aec6kM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviews_ints = []\n",
        "for review in np.asarray(clean_data):\n",
        "    reviews_ints.append([vocab_to_int[word] for word in review])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7ilA3HFKjib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_features(reviews_ints, seq_length):\n",
        "    padded_list = []\n",
        "    for review in reviews_ints:\n",
        "        if len(review) < seq_length:\n",
        "            diff = seq_length - len(review)\n",
        "            review = [0]*diff + review\n",
        "        padded_list.append(review[:seq_length])\n",
        "    return np.asarray(padded_list)\n",
        "\n",
        "seq_length = len(max(reviews_ints, key=len))\n",
        "\n",
        "features = pad_features(reviews_ints, seq_length=seq_length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irru_1vBBSmG",
        "colab_type": "text"
      },
      "source": [
        "Wrapping the data in torch TensorDataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpWP2vlahkbQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = features\n",
        "y = np.asarray(data_clean['senti_score'])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3)\n",
        "\n",
        "train_data = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
        "test_data = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))\n",
        "\n",
        "batch_size_train = 35\n",
        "batch_size_test = 30\n",
        "\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size_train)\n",
        "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGAfxuwVAmJS",
        "colab_type": "text"
      },
      "source": [
        "LSTM model definition which will be used to perform Sentiment Analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpbO0mb83MDi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SentimentLSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
        "        super(SentimentLSTM, self).__init__()\n",
        "\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "        \n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n",
        "                            dropout=drop_prob, batch_first=True)\n",
        "        \n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "        self.sig = nn.Sigmoid()\n",
        "        \n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        batch_size = x.size(0)\n",
        "        \n",
        "        embeds = self.embedding(x)\n",
        "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
        "        \n",
        "        out = self.dropout(lstm_out)\n",
        "        out = self.fc(out)\n",
        "\n",
        "        sig_out = self.sig(out)\n",
        "        sig_out = sig_out.view(batch_size, -1)\n",
        "        sig_out = sig_out[:, -1] \n",
        "        \n",
        "        return sig_out, hidden\n",
        "    \n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        weight = next(self.parameters()).data\n",
        "        \n",
        "        if (train_on_gpu):\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
        "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
        "        else:\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
        "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
        "        \n",
        "        return hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoQgwbW_eFEk",
        "colab_type": "code",
        "outputId": "64708d54-4c01-4d8d-c49d-39f070aac603",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "train_on_gpu=torch.cuda.is_available()\n",
        "\n",
        "vocab_size = len(vocab_to_int)+1 \n",
        "output_size = 1\n",
        "embedding_dim = 16\n",
        "hidden_dim = 128\n",
        "n_layers = 2\n",
        "\n",
        "net = SentimentLSTM(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
        "\n",
        "print(net)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SentimentLSTM(\n",
            "  (embedding): Embedding(1744, 16)\n",
            "  (lstm): LSTM(16, 128, num_layers=2, batch_first=True, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
            "  (sig): Sigmoid()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHEnraWjQTNx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr=0.01\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JWwkFWG7U4G",
        "colab_type": "code",
        "outputId": "a705cdba-e68d-4a2e-94a8-26543b0975a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "epochs = 4 \n",
        "\n",
        "counter = 0\n",
        "print_every = 4\n",
        "clip=5 \n",
        "\n",
        "if(train_on_gpu):\n",
        "    net.cuda()\n",
        "\n",
        "net.train()\n",
        "\n",
        "for e in range(epochs):\n",
        "    h = net.init_hidden(batch_size_train)\n",
        "  \n",
        "    for inputs, labels in train_loader:\n",
        "        counter += 1\n",
        "        if(train_on_gpu):\n",
        "            inputs, labels = inputs.cuda(), labels.cuda()\n",
        "        h = tuple([each.data for each in h])\n",
        "        net.zero_grad()\n",
        "        output, h = net(inputs, h)\n",
        "\n",
        "        loss = criterion(output.squeeze(), labels.float())\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        \n",
        "        if counter % print_every == 0:\n",
        "          print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
        "                \"Step: {}...\".format(counter),\n",
        "                \"Loss: {:.6f}...\".format(loss.item()))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/4... Step: 4... Loss: 0.657721...\n",
            "Epoch: 1/4... Step: 8... Loss: 0.676270...\n",
            "Epoch: 1/4... Step: 12... Loss: 0.683351...\n",
            "Epoch: 1/4... Step: 16... Loss: 0.660371...\n",
            "Epoch: 1/4... Step: 20... Loss: 0.705865...\n",
            "Epoch: 2/4... Step: 24... Loss: 0.655850...\n",
            "Epoch: 2/4... Step: 28... Loss: 0.612159...\n",
            "Epoch: 2/4... Step: 32... Loss: 0.534427...\n",
            "Epoch: 2/4... Step: 36... Loss: 0.704319...\n",
            "Epoch: 2/4... Step: 40... Loss: 0.533397...\n",
            "Epoch: 3/4... Step: 44... Loss: 0.555116...\n",
            "Epoch: 3/4... Step: 48... Loss: 0.400504...\n",
            "Epoch: 3/4... Step: 52... Loss: 0.362035...\n",
            "Epoch: 3/4... Step: 56... Loss: 0.458963...\n",
            "Epoch: 3/4... Step: 60... Loss: 0.348555...\n",
            "Epoch: 4/4... Step: 64... Loss: 0.249374...\n",
            "Epoch: 4/4... Step: 68... Loss: 0.134352...\n",
            "Epoch: 4/4... Step: 72... Loss: 0.497276...\n",
            "Epoch: 4/4... Step: 76... Loss: 0.429628...\n",
            "Epoch: 4/4... Step: 80... Loss: 0.074242...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fX7MpsU47V8W",
        "colab_type": "code",
        "outputId": "95cd1757-a7ba-445f-c75e-873b3ac46d6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "test_losses = []\n",
        "num_correct = 0\n",
        "\n",
        "h = net.init_hidden(batch_size_test)\n",
        "\n",
        "net.eval()\n",
        "\n",
        "for inputs, labels in test_loader:\n",
        "    h = tuple([each.data for each in h])\n",
        "\n",
        "    if(train_on_gpu):\n",
        "        inputs, labels = inputs.cuda(), labels.cuda()\n",
        "    \n",
        "    output, h = net(inputs, h)\n",
        "    \n",
        "    test_loss = criterion(output.squeeze(), labels.float())\n",
        "    test_losses.append(test_loss.item())\n",
        "    \n",
        "    pred = torch.round(output.squeeze())\n",
        "    correct_tensor = pred.eq(labels.float().view_as(pred))\n",
        "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
        "    num_correct += np.sum(correct)\n",
        "\n",
        "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
        "\n",
        "test_acc = num_correct/len(test_loader.dataset)\n",
        "print(\"Test accuracy: {:.3f}\".format(test_acc))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.699\n",
            "Test accuracy: 0.693\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jvh0ipm_AWx7",
        "colab_type": "text"
      },
      "source": [
        "Predicting on a test statement."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kN-zvWHYBbXO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_review_neg = 'bad phone.'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhS8xqcbBmhr",
        "colab_type": "code",
        "outputId": "14d29cc8-7420-4bde-e7ed-94fa5277c8a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from string import punctuation\n",
        "\n",
        "def tokenize_review(test_review):\n",
        "    test_review = test_review.lower() \n",
        "    test_text = ''.join([c for c in test_review if c not in punctuation])\n",
        "    test_words = test_text.split()\n",
        "    test_ints = []\n",
        "    test_ints.append([vocab_to_int[word] for word in test_words])\n",
        "\n",
        "    return test_ints\n",
        "    \n",
        "test_ints = tokenize_review(test_review_neg)\n",
        "print(test_ints)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[58, 2]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFudepBTBnd0",
        "colab_type": "code",
        "outputId": "7350bb7f-0fb0-44e9-afa4-750986acc9b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "features = pad_features(test_ints, seq_length)\n",
        "\n",
        "feature_tensor = torch.from_numpy(features)\n",
        "print(feature_tensor.size())"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 16])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twJ7U0UZBz5t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(net, test_review, sequence_length=200):\n",
        "    \n",
        "    net.eval()\n",
        "\n",
        "    test_ints = tokenize_review(test_review)\n",
        "    seq_length=sequence_length\n",
        "    features = pad_features(test_ints, seq_length)\n",
        "    \n",
        "    feature_tensor = torch.from_numpy(features)\n",
        "    \n",
        "    batch_size = feature_tensor.size(0)\n",
        "\n",
        "    h = net.init_hidden(batch_size)\n",
        "    \n",
        "    if(train_on_gpu):\n",
        "        feature_tensor = feature_tensor.cuda()\n",
        "    \n",
        "    output, h = net(feature_tensor, h)\n",
        "\n",
        "    pred = torch.round(output.squeeze()) \n",
        "    print('Prediction value: {:.6f}'.format(output.item()))\n",
        "    \n",
        "    if(pred.item()==1):\n",
        "        print(\"Positive review!\")\n",
        "    else:\n",
        "        print(\"Negative review!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UPAh5hrB6zj",
        "colab_type": "code",
        "outputId": "b3ebd5c6-32c9-4a27-cc38-d0bf0912cbf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "predict(net, test_review_neg, seq_length)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction value: 0.022982\n",
            "Negative review!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMqVhiNeZS1L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}